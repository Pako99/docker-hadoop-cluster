IMAGE_VER=hadoop-spark:v5
HIVE_EXTERNAL=false # if true, you should start docker compose with '--profile hiveexternal'
NODE_REPLICAS=2 # number of worker nodes

# SPARK USERNAME AND PASSWORD
SYS_USERNAME=spark
SYS_PASSWORD=spark

# POSTGRES USERNAME AND PASSWORD (if HIVE_EXTERNAL true)
PSQL_PGUSER=postgres
PSQL_PGPASSWORD=spark
PSQL_DBNAME=hive_metastore
